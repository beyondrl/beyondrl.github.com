---
---
References
==========

@article{kurutach_learning_2018,
	title = {Learning Plannable Representations with Causal {InfoGAN}},
	url = {http://arxiv.org/abs/1807.09341},
	abstract = {In recent years, deep generative models have been shown to 'imagine' convincing high-dimensional observations such as images, audio, and even video, learning directly from raw data. In this work, we ask how to imagine goal-directed visual plans -- a plausible sequence of observations that transition a dynamical system from its current configuration to a desired goal state, which can later be used as a reference trajectory for control. We focus on systems with high-dimensional observations, such as images, and propose an approach that naturally combines representation learning and planning. Our framework learns a generative model of sequential observations, where the generative process is induced by a transition in a low-dimensional planning model, and an additional noise. By maximizing the mutual information between the generated observations and the transition in the planning model, we obtain a low-dimensional representation that best explains the causal nature of the data. We structure the planning model to be compatible with efficient planning algorithms, and we propose several such models based on either discrete or continuous states. Finally, to generate a visual plan, we project the current and goal observations onto their respective states in the planning model, plan a trajectory, and then use the generative model to transform the trajectory to a sequence of observations. We demonstrate our method on imagining plausible visual plans of rope manipulation.},
	journaltitle = {{arXiv}:1807.09341 [cs, stat]},
	author = {Kurutach, Thanard and Tamar, Aviv and Yang, Ge and Russell, Stuart and Abbeel, Pieter},
	urldate = {2019-11-28},
	date = {2018-07-24},
	eprinttype = {arxiv},
	eprint = {1807.09341},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Neural and Evolutionary Computing, Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Robotics},
	file = {arXiv Fulltext PDF:/home/tijs/Zotero/storage/PKCXGXTT/Kurutach et al. - 2018 - Learning Plannable Representations with Causal Inf.pdf:application/pdf;arXiv.org Snapshot:/home/tijs/Zotero/storage/JYHIKXBB/1807.html:text/html}
}

@article{chen_infogan:_2016,
	title = {{InfoGAN}: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets},
	url = {http://arxiv.org/abs/1606.03657},
	shorttitle = {{InfoGAN}},
	abstract = {This paper describes {InfoGAN}, an information-theoretic extension to the Generative Adversarial Network that is able to learn disentangled representations in a completely unsupervised manner. {InfoGAN} is a generative adversarial network that also maximizes the mutual information between a small subset of the latent variables and the observation. We derive a lower bound to the mutual information objective that can be optimized efficiently, and show that our training procedure can be interpreted as a variation of the Wake-Sleep algorithm. Specifically, {InfoGAN} successfully disentangles writing styles from digit shapes on the {MNIST} dataset, pose from lighting of 3D rendered images, and background digits from the central digit on the {SVHN} dataset. It also discovers visual concepts that include hair styles, presence/absence of eyeglasses, and emotions on the {CelebA} face dataset. Experiments show that {InfoGAN} learns interpretable representations that are competitive with representations learned by existing fully supervised methods.},
	journaltitle = {{arXiv}:1606.03657 [cs, stat]},
	author = {Chen, Xi and Duan, Yan and Houthooft, Rein and Schulman, John and Sutskever, Ilya and Abbeel, Pieter},
	urldate = {2019-11-28},
	date = {2016-06-11},
	eprinttype = {arxiv},
	eprint = {1606.03657},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:/home/tijs/Zotero/storage/AA5TA8BZ/Chen et al. - 2016 - InfoGAN Interpretable Representation Learning by .pdf:application/pdf;arXiv.org Snapshot:/home/tijs/Zotero/storage/6CGL4V2S/1606.html:text/html}
}