---
---
References
==========

@article{schrittwieser_mastering_2019,
	title = {Mastering Atari, Go, Chess and Shogi by Planning with a Learned Model},
	url = {http://arxiv.org/abs/1911.08265},
	abstract = {Constructing agents with planning capabilities has long been one of the main challenges in the pursuit of artificial intelligence. Tree-based planning methods have enjoyed huge success in challenging domains, such as chess and Go, where a perfect simulator is available. However, in real-world problems the dynamics governing the environment are often complex and unknown. In this work we present the {MuZero} algorithm which, by combining a tree-based search with a learned model, achieves superhuman performance in a range of challenging and visually complex domains, without any knowledge of their underlying dynamics. {MuZero} learns a model that, when applied iteratively, predicts the quantities most directly relevant to planning: the reward, the action-selection policy, and the value function. When evaluated on 57 different Atari games - the canonical video game environment for testing {AI} techniques, in which model-based planning approaches have historically struggled - our new algorithm achieved a new state of the art. When evaluated on Go, chess and shogi, without any knowledge of the game rules, {MuZero} matched the superhuman performance of the {AlphaZero} algorithm that was supplied with the game rules.},
	journaltitle = {{arXiv}:1911.08265 [cs, stat]},
	author = {Schrittwieser, Julian and Antonoglou, Ioannis and Hubert, Thomas and Simonyan, Karen and Sifre, Laurent and Schmitt, Simon and Guez, Arthur and Lockhart, Edward and Hassabis, Demis and Graepel, Thore and Lillicrap, Timothy and Silver, David},
	urldate = {2019-12-09},
	date = {2019-11-19},
	eprinttype = {arxiv},
	eprint = {1911.08265},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:/home/tijs/Zotero/storage/WAXPQS24/Schrittwieser et al. - 2019 - Mastering Atari, Go, Chess and Shogi by Planning w.pdf:application/pdf;arXiv.org Snapshot:/home/tijs/Zotero/storage/SLFCLZG6/1911.html:text/html}
}

@article{silver_mastering_2017,
	title = {Mastering Chess and Shogi by Self-Play with a General Reinforcement Learning Algorithm},
	url = {http://arxiv.org/abs/1712.01815},
	abstract = {The game of chess is the most widely-studied domain in the history of artificial intelligence. The strongest programs are based on a combination of sophisticated search techniques, domain-specific adaptations, and handcrafted evaluation functions that have been refined by human experts over several decades. In contrast, the {AlphaGo} Zero program recently achieved superhuman performance in the game of Go, by tabula rasa reinforcement learning from games of self-play. In this paper, we generalise this approach into a single {AlphaZero} algorithm that can achieve, tabula rasa, superhuman performance in many challenging domains. Starting from random play, and given no domain knowledge except the game rules, {AlphaZero} achieved within 24 hours a superhuman level of play in the games of chess and shogi (Japanese chess) as well as Go, and convincingly defeated a world-champion program in each case.},
	journaltitle = {{arXiv}:1712.01815 [cs]},
	author = {Silver, David and Hubert, Thomas and Schrittwieser, Julian and Antonoglou, Ioannis and Lai, Matthew and Guez, Arthur and Lanctot, Marc and Sifre, Laurent and Kumaran, Dharshan and Graepel, Thore and Lillicrap, Timothy and Simonyan, Karen and Hassabis, Demis},
	urldate = {2019-12-11},
	date = {2017-12-05},
	eprinttype = {arxiv},
	eprint = {1712.01815},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
	file = {arXiv Fulltext PDF:/home/tijs/Zotero/storage/FW7B3U62/Silver et al. - 2017 - Mastering Chess and Shogi by Self-Play with a Gene.pdf:application/pdf;arXiv.org Snapshot:/home/tijs/Zotero/storage/YJCCSWSW/1712.html:text/html}
}

@article{silver_mastering_2016,
	title = {Mastering the game of Go with deep neural networks and tree search},
	volume = {529},
	rights = {2016 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/nature16961},
	doi = {10.1038/nature16961},
	abstract = {A computer Go program based on deep neural networks defeats a human professional player to achieve one of the grand challenges of artificial intelligence.},
	pages = {484--489},
	number = {7587},
	journaltitle = {Nature},
	author = {Silver, David and Huang, Aja and Maddison, Chris J. and Guez, Arthur and Sifre, Laurent and van den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and Dieleman, Sander and Grewe, Dominik and Nham, John and Kalchbrenner, Nal and Sutskever, Ilya and Lillicrap, Timothy and Leach, Madeleine and Kavukcuoglu, Koray and Graepel, Thore and Hassabis, Demis},
	urldate = {2019-12-17},
	date = {2016-01},
	langid = {english},
	file = {Full Text PDF:/home/tijs/Zotero/storage/5FK25BTM/Silver et al. - 2016 - Mastering the game of Go with deep neural networks.pdf:application/pdf;Snapshot:/home/tijs/Zotero/storage/QSB4VPQZ/nature16961.html:text/html}
}