---
---
References
==========

@article{peng_mcp_nodate,
	title = {{MCP}: Learning Composable Hierarchical Control with Multiplicative Compositional Policies},
	pages = {21},
	author = {Peng, Xue Bin and Chang, Michael and Zhang, Grace and Abbeel, Pieter and Levine, Sergey},
	langid = {english},
	file = {Peng et al. - MCP Learning Composable Hierarchical Control with.pdf:/home/tijs/Zotero/storage/IXEBWTMZ/Peng et al. - MCP Learning Composable Hierarchical Control with.pdf:application/pdf}
}

@inproceedings{stolle_learning_2002,
	title = {Learning Options in Reinforcement Learning},
	abstract = {Temporally extended actions (e.g., macro actions) have proven very  useful in speeding up learning, ensuring robustness and building prior knowledge  into {AI} systems. The options framework (Precup, 2000; Sutton, Precup \& Singh,  1999) provides a natural way of incorporating such actions into reinforcement  learning systems, but leaves open the issue of how good options might be identified.},
	pages = {212--223},
	booktitle = {Lecture Notes in Computer Science},
	author = {Stolle, Martin and Precup, Doina},
	date = {2002},
	file = {Citeseer - Full Text PDF:/home/tijs/Zotero/storage/NV48WNTI/Stolle and Precup - 2002 - Learning Options in Reinforcement Learning.pdf:application/pdf;Citeseer - Snapshot:/home/tijs/Zotero/storage/R8RGNYTS/summary.html:text/html}
}